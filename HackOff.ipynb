{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HackOff.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jxQFrKPFTyG"
      },
      "source": [
        "# **Brain Tumor Detection Web App**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvfBGoaRCz6w"
      },
      "source": [
        "!pip install  -U ipykernel #updating to latest ipykernel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0ImYdLGDt4U"
      },
      "source": [
        "!python --version #checking the python version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ieCBOsuDyh6"
      },
      "source": [
        "!pip install streamlit #installing streamlit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWcwX9sOD6Yt"
      },
      "source": [
        "!pip install pyngrok #installing ngrok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivtRI8zmERiu",
        "outputId": "6bc50656-adf3-410f-e663-dfb3f243b670"
      },
      "source": [
        "%%writefile app.py \r\n",
        "#importing all the required libraries\r\n",
        "import streamlit as st \r\n",
        "import tensorflow as tf\r\n",
        "import cv2\r\n",
        "import keras\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, BatchNormalization, Flatten\r\n",
        "import numpy as np\r\n",
        "from PIL import Image ,ImageOps\r\n",
        "\r\n",
        "\r\n",
        "st.set_option('deprecation.showfileUploaderEncoding',False) #on loading a streamlit app we get a warning, this line prevents us from getting that warning\r\n",
        "\r\n",
        "@st.cache(allow_output_mutation=True) #this line prevent us from loading the model again and again and will help in storing the model in cache once it has been loaded\r\n",
        "\r\n",
        "def load_model(): #loading our model\r\n",
        "  model = tf.keras.models.load_model('/content/BrainTumorModel .h5')\r\n",
        "  return model\r\n",
        "\r\n",
        "model = load_model()\r\n",
        "#defining the header or title of the page that the user will be seeing. We also make a side bar for the web app\r\n",
        "\r\n",
        "st.markdown(\"<h1 style='text-align: center; color: Black;'>Brain Tumor Classifier</h1>\", unsafe_allow_html=True)\r\n",
        "st.markdown(\"<h3 style='text-align: center; color: Black;'>All you have to do is Upload the MRI scan and the model will do the rest!</h3>\", unsafe_allow_html=True)\r\n",
        "st.markdown(\"<h4 style='text-align: center; color: Black;'>Submission for HackOff V3.0</h4>\", unsafe_allow_html=True)\r\n",
        "st.sidebar.header(\"What is this Project about?\")\r\n",
        "st.sidebar.text(\"It is a Deep learning solution to detection of Brain Tumor using MRI Scans.\")\r\n",
        "st.sidebar.header(\"What does it do?\")\r\n",
        "st.sidebar.text(\"The user can upload their MRI scan and the model will try to predict whether or not the user has Brain Tumor or not.\")\r\n",
        "st.sidebar.header(\"What tools where used to make this?\")\r\n",
        "st.sidebar.text(\"The Model was made using a dataset from Kaggle along with using Kaggle notebooks to train the model. We made use of Tensorflow, Keras as well as some other Python Libraries to make this complete project. To deply it on web, we used ngrok and Streamlit!\")\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "file=st.file_uploader(\"Please upload your MRI Scan\",type = [\"jpg\",\"png\"]) #accepting the image input from the user\r\n",
        "\r\n",
        "def import_and_predict(image_data,model): #our prediction method that will accept the data and the model and would give us a prediction\r\n",
        "  #pre-processing the image before it is fed to the model\r\n",
        "  size = (150,150)\r\n",
        "  image1 = ImageOps.fit(image_data,size,Image.ANTIALIAS)\r\n",
        "  image = ImageOps.grayscale(image1)\r\n",
        "  img = np.asarray(image)\r\n",
        "  img_reshape = img[np.newaxis,...]\r\n",
        "  #img_reshape = img_reshape/255.0\r\n",
        "  img_reshape = img.reshape(1,150,150,1)\r\n",
        "  prediction = model.predict(img_reshape)\r\n",
        "  return prediction\r\n",
        "\r\n",
        "if file is None: #initial condition when no image has been uploaded by the user\r\n",
        "  st.markdown(\"<h5 style='text-align: center; color: Black;'>Please Upload a File</h5>\", unsafe_allow_html=True)\r\n",
        "else: #condition to give the result once the user has input the image \r\n",
        "  image = Image.open(file)\r\n",
        "  st.image(image,use_column_width = True)\r\n",
        "  predictions = import_and_predict(image,model)\r\n",
        "  class_names = ['glioma_tumor','meningioma_tumor','no_tumor','pituitary_tumor']\r\n",
        "  string = \"The patient most likely has:\"+ class_names[np.argmax(predictions)]\r\n",
        "  st.success(string)\r\n",
        "  #st.success(predictions)\r\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqLF3T3kPJu0",
        "outputId": "81c5263c-3d0c-4334-ab79-aa2200ca6403"
      },
      "source": [
        "!ngrok authtoken 1lSl5RMkADZ2p4HYnMk3ZQcqzNw_5KvvAFxRwEPJz9UcboW7R  "
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNlPN3QsPlfp",
        "outputId": "e54b4f43-26fe-4858-8c39-d593f71d0cd5"
      },
      "source": [
        "!nohup streamlit run app.py & #running our app"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2A6I9JGPu5K",
        "outputId": "7ecbf406-6744-42bb-fc02-96ac066c4e2f"
      },
      "source": [
        "from pyngrok import ngrok  #creating the ngrok tunnel\r\n",
        "url = ngrok.connect(port = 8501)\r\n",
        "url"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"http://b2c3d4b05d4f.ngrok.io\" -> \"http://localhost:80\">"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGJfjOM5WwZ2",
        "outputId": "88689db6-d002-4319-fe90-b46420ca50f9"
      },
      "source": [
        "!streamlit run --server.port 80 app.py >/dev/null #running our server so that we can access the app"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-11 18:28:44.520957: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-12-11 18:28:45.980943: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-12-11 18:28:45.990977: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-12-11 18:28:45.991040: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a7700dd7da86): /proc/driver/nvidia/version does not exist\n",
            "2020-12-11 18:28:45.997479: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300000000 Hz\n",
            "2020-12-11 18:28:45.997717: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1a6b9c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-12-11 18:28:45.997756: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T898OAgcTtHk"
      },
      "source": [
        "!killall ngrok #command if we wish to kill all the previously created tunnels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgY9JX6AfNIz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}